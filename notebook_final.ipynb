{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Projet de programmation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Introduction <a name=\"intro\"></a>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Il faut récupèrer le projet avec : \n",
    "\n",
    "    git clone https://github.com/gwatkinson/projet-python-twitter.git"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Puis, il faut créer le fichier `projet/_credentials.py`, qui contient les clés de l'API de Twitter.\n",
    "\n",
    "Dans le format suivant :\n",
    "\n",
    "```python\n",
    "credentials = {\n",
    "    \"consumer_key\": \"XXXXXXX\",\n",
    "    \"consumer_secret\": \"XXXXXXX\",\n",
    "    \"access_token\": \"XXXXXXX\",\n",
    "    \"access_token_secret\": \"XXXXXXX\",\n",
    "}\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Finalement, il suffit d'executer les cellules de ce notebook dans l'ordre."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Table des matières\n",
    "\n",
    "* [Introduction](#intro)\n",
    "* [1)Récupération des données](#data)\n",
    "* [2)Modélisation](#model)\n",
    "    * [a.Prepocessing](#process)\n",
    "    * [b.Clustering](#cluster)\n",
    "* [3)Visualisation](#visu)\n",
    "    * [a.Nuages de mots](#cloud)\n",
    "    * [b.Carte interactive](#map)\n",
    "* [Conclusion](#conc)\n",
    "* [Annexes](#annex)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1) Récupération des données <a name=\"data\"></a>\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Nous avons utilisé l'**API** de Twitter pour récupérer les nouveaux tweets publiés sur Twitter, la nuit du 3 au 4 Novembre 2020 (la nuit de l'éléction américaine). Nous avons seulement récupérer les tweets qui contennaient certains mots :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste 3 sur Trump et Biden uniquement\n",
    "liste_3 = [\n",
    "    \"biden\",\n",
    "    \"trump\",\n",
    "    \"JoeBiden\",\n",
    "    \"realDonaldTrump\",\n",
    "]\n",
    "\n",
    "# Liste 4 sur le thème 'vote'\n",
    "liste_4 = [\n",
    "    \"iwillvote\",\n",
    "    \"govote\",\n",
    "    \"uselection\",\n",
    "    \"vote\",\n",
    "]\n",
    "\n",
    "# Liste 5 sur le thème 'election'\n",
    "liste_5 = [\n",
    "    \"uselection\",\n",
    "    \"president\",\n",
    "    \"presidentialelection\",\n",
    "    \"presidential\",\n",
    "    \"electionnight\",\n",
    "]"
   ]
  },
  {
   "source": [
    "Pour cela, nous avons utilisé le module python `tweepy` ainsi que les fonctions codées dans le module `streaming` (voir la documentation pour plus d'information sur [`start_stream`](https://gwatkinson.github.io/projet-python-twitter/streaming.html#projet_python_twitter.streaming.start_stream)). Voici un exemple d'utilisation du code que nous avons écrit :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import projet.streaming as stream                           # Contient les fonctions pour le streaming\n",
    "import projet.listes_mots as listes                         # Contient les listes de mots\n",
    "import projet._credentials as cred                          # Contient les clés d'authentification à l'API\n",
    "\n",
    "credentials = stream.CredentialsClass(cred.credentials)     # Pour se connecter à l'API (il faut le fichier projet/_credentials.py)\n",
    "\n",
    "stream.start_stream(\n",
    "    credentials=credentials,\n",
    "    liste_mots=listes.liste_3,                              # Liste des mots à tracker (voir `projet.listes_mots`)\n",
    "    nb=200,                                                 # Nombre de tweets à recupérer\n",
    "    # timeout=10/3600,                                        # Durée du stream\n",
    "    fprefix=\"exemple_liste_3\",                              # À modifier en fonction de la liste selectionnée\n",
    "    path=\"./data/json/\",                                    # À modifier selon l'utilisateur (doit finir par \"/\" ou \"\\\")\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "source": [
    "Un fichier `json` a été créé dans `data/json/`.\n",
    "\n",
    "Pour voir à quoi ressemble les données :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "path = glob.glob(\"data/json/exemple_liste_3*.json\")[-1]  # On récupère le dernier fichier exemple crée\n",
    "print(\"On regarde le fichier : \"+path+\"\\n\")\n",
    "\n",
    "tweets_list = []\n",
    "with open(path, \"r\") as fh:\n",
    "    file = fh.read().split(\"\\n\")\n",
    "    for line in file:\n",
    "        if line:\n",
    "            tweets_list.append(json.loads(line))\n",
    "\n",
    "print(\"Le premier tweet :\")\n",
    "print(tweets_list[0])\n"
   ]
  },
  {
   "source": [
    "Il s'agit du format `json`. Il est difficile de voir les variable comme cela. On peut créer une `dataframe pandas` pour mieux comprendre les données."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = pd.DataFrame(tweets_list)\n",
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dimensions : \", df_tweets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Colonnes :\\n\")\n",
    "for name in list(df_tweets):\n",
    "    print(name)"
   ]
  },
  {
   "source": [
    "## 2) Modélisation <a name=\"model\"></a>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### a. Preprocessing <a name=\"process\"></a>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Nous avons fait une fonction qui fait les étapes précédentes ainsi que des fonctions pour nettoyer les données. Elles sont dans le fichier `processing.py`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import projet.processing as process                         # Contient les fonctions pour le processing de la dataframe\n",
    "\n",
    "folder = \"./data/json/\"                                     # Pour écupèrer tous les fichiers json dans le dossier 'data/json/'\n",
    "\n",
    "dirty_df = process.tweet_json_to_df(folder=folder, verbose=True)     # Convertit les json en dataframe pandas\n"
   ]
  },
  {
   "source": [
    "Nous avons ainsi récupérer les fichiers dans `data/json/` dans la dataframe pandas `dirty_df`.\n",
    "\n",
    "Elle ressemble à :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "dirty_df.head()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "On peut ensuite utiliser `clean_df` pour filtrer et nettoyer la base de donnée en conservant seulement les informations qui nous interressent. On peut aussi utiliser une liste de `listes_variables` pour récupérer d'autres variables ou en ajouter dans l'option `extra` de `clean_df`. Voir la doc pour plus de détails : [`clean_df`](https://gwatkinson.github.io/projet-python-twitter/projet/processing.html#projet.processing.clean_df)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = process.clean_df(dirty_df, index=\"id\", date=\"created_at\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = process.get_full_text(clean_df, new_var=\"full_text\", drop_vars=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politic_df = process.add_politics(text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politic_df[[\"full_text\", \"full_text-contains_trump\", \"full_text-contains_biden\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df = process.add_sentiment(politic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df[\"full_textAjout-sentiment-compound\"].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = process.sentiment_class(sentiment_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(final_df[\"user-description-contains_trump\"].isnull())/len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(~final_df[\"user-location\"].isnull())/len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import projet.modelisation as model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_mat = model.standardize(final_df, model.get_numeric(final_df.drop(\"user-id\", axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans, sse = model.add_group(std_mat, max_cluster=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.plot(range(1, 31), sse)\n",
    "plt.xticks(range(1, 31))\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "source": [
    "### b. Clustering <a name=\"cluster\"></a>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 3) Visualisation <a name=\"visu\"></a>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### a. Nuages de mots <a name=\"cloud\"></a>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### b. Carte interactive <a name=\"map\"></a>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Conclusion <a name=\"conc\"></a>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Annexes <a name=\"annex\"></a>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}