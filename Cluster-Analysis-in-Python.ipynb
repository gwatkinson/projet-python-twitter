{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x y les coordonnnées et df la dataframe\n",
    "\n",
    "\n",
    "\n",
    "#Clustering hierachique\n",
    "\n",
    "# Import linkage and fcluster functions\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "\n",
    "# Use the linkage() function to compute distances\n",
    "Z = linkage(df, 'ward')\n",
    "\n",
    "# Generate cluster labels\n",
    "df['cluster_labels'] = fcluster(Z, 2, criterion='maxclust')\n",
    "\n",
    "# Plot the points with seaborn\n",
    "sns.scatterplot(x='x', y='y', hue='cluster_labels', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clustering K-means\n",
    "\n",
    "\n",
    "# Import kmeans and vq functions\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "\n",
    "# Compute cluster centers\n",
    "centroids,_ = kmeans(df, 2)\n",
    "\n",
    "# Assign cluster labels\n",
    "df['cluster_labels'], _ = vq(df, centroids)\n",
    "\n",
    "# Plot the points with seaborn\n",
    "sns.scatterplot(x='x', y='y', hue='cluster_labels', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalisation d'un vecteur (dimension 1 ou multiple)\n",
    "\n",
    "# Import the whiten function\n",
    "from scipy.cluster.vq import whiten\n",
    "\n",
    "goals_for = [4,3,2,3,1,1,2,0,1,4]\n",
    "\n",
    "# Use the whiten() function to standardize the data\n",
    "scaled_data = whiten(goals_for)\n",
    "print(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparer les 2 set de donnnées avant apres traitement\n",
    "\n",
    "# Plot original data\n",
    "plt.plot(goals_for, label='original')\n",
    "\n",
    "# Plot scaled data\n",
    "plt.plot(scaled_data, label='scaled')\n",
    "\n",
    "# Show the legend in the plot\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2tudie  2 colonnes \n",
    "\n",
    "# Scale wage and value\n",
    "fifa['scaled_wage'] = whiten(fifa['eur_wage'])\n",
    "fifa['scaled_value'] = whiten(fifa['eur_value'])\n",
    "\n",
    "# Plot the two columns in a scatter plot\n",
    "fifa.plot(x='scaled_wage', y='scaled_value', kind = 'scatter')\n",
    "plt.show()\n",
    "\n",
    "# Check mean and standard deviation of scaled values\n",
    "print(fifa[['scaled_wage', 'scaled_value']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Import the fcluster and linkage functions\n",
    "from scipy.cluster.hierarchy import fcluster, linkage\n",
    "\n",
    "# Use the linkage() function\n",
    "distance_matrix = linkage(comic_con[['x_scaled', 'y_scaled']], method = 'ward', metric = 'euclidean')\n",
    "\n",
    "# Assign cluster labels\n",
    "comic_con['cluster_labels'] = fcluster(distance_matrix, 2, criterion='maxclust')\n",
    "\n",
    "# Plot clusters\n",
    "sns.scatterplot(x='x_scaled', y='y_scaled', \n",
    "                hue='cluster_labels', data = comic_con)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour faire les dendogrammes\n",
    "\n",
    "# Import the dendrogram function\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "# Create a dendrogram\n",
    "dn = dendrogram(distance_matrix)\n",
    "\n",
    "# Display the dendogram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical clustering big picture\n",
    "\n",
    "\n",
    "# Fit the data into a hierarchical clustering algorithm\n",
    "distance_matrix = linkage(fifa[['scaled_sliding_tackle', 'scaled_aggression']], 'ward')\n",
    "\n",
    "# Assign cluster labels to each row of data\n",
    "fifa['cluster_labels'] = fcluster(distance_matrix, 3, criterion='maxclust')\n",
    "\n",
    "# Display cluster centers of each cluster\n",
    "print(fifa[['scaled_sliding_tackle', 'scaled_aggression', 'cluster_labels']].groupby('cluster_labels').mean())\n",
    "\n",
    "# Create a scatter plot through seaborn\n",
    "sns.scatterplot(x='scaled_sliding_tackle', y='scaled_aggression', hue='cluster_labels', data=fifa)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the kmeans and vq functions\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "\n",
    "# Generate cluster centers\n",
    "cluster_centers, distortion = kmeans(comic_con[['x_scaled','y_scaled']],2)\n",
    "\n",
    "# Assign cluster labels\n",
    "comic_con['cluster_labels'], distortion_list = vq(comic_con[['x_scaled','y_scaled']],cluster_centers)\n",
    "\n",
    "# Plot clusters\n",
    "sns.scatterplot(x='x_scaled', y='y_scaled', \n",
    "                hue='cluster_labels', data = comic_con)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elbow Method\n",
    "\n",
    "distortions = []\n",
    "num_clusters = range(1, 7)\n",
    "\n",
    "# Create a list of distortions from the kmeans function\n",
    "for i in num_clusters:\n",
    "    cluster_centers, distortion = kmeans(comic_con[['x_scaled','y_scaled']],i)\n",
    "    distortions.append(distortion)\n",
    "\n",
    "# Create a data frame with two lists - num_clusters, distortions\n",
    "elbow_plot = pd.DataFrame({'num_clusters': num_clusters, 'distortions': distortions})\n",
    "\n",
    "# Creat a line plot of num_clusters and distortions\n",
    "sns.lineplot(x='num_clusters', y='distortions', data = elbow_plot)\n",
    "plt.xticks(num_clusters)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distortions = []\n",
    "num_clusters = range(2, 7)\n",
    "\n",
    "# Create a list of distortions from the kmeans function\n",
    "for i in num_clusters:\n",
    "    cluster_centers, distortion = kmeans(uniform_data[['x_scaled','y_scaled']],i)\n",
    "    distortions.append(distortion)\n",
    "\n",
    "# Create a data frame with two lists - number of clusters and distortions\n",
    "elbow_plot = pd.DataFrame({'num_clusters': num_clusters, 'distortions': distortions})\n",
    "\n",
    "# Creat a line plot of num_clusters and distortions\n",
    "sns.lineplot(x='num_clusters', y='distortions', data=elbow_plot)\n",
    "plt.xticks(num_clusters)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same que au dessus ?\n",
    "\n",
    "# Set up a random seed in numpy\n",
    "random.seed([1000,2000])\n",
    "\n",
    "# Fit the data into a k-means algorithm\n",
    "cluster_centers,_ = kmeans(fifa[['scaled_def', 'scaled_phy']], 3)\n",
    "\n",
    "# Assign cluster labels\n",
    "fifa['cluster_labels'], _ = vq(fifa[['scaled_def', 'scaled_phy']], cluster_centers)\n",
    "\n",
    "# Display cluster centers \n",
    "print(fifa[['scaled_def', 'scaled_phy', 'cluster_labels']].groupby('cluster_labels').mean())\n",
    "\n",
    "# Create a scatter plot through seaborn\n",
    "sns.scatterplot(x='scaled_def', y='scaled_phy', hue='cluster_labels', data=fifa)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Le dernier chapitre porte sur l'utilisation dans le monde réelle de ces techniques notamment pour analyse couleur d'images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import image class of matplotlib\n",
    "from matplotlib import image as img\n",
    "\n",
    "# Read batman image and print dimensions\n",
    "batman_image = img.imread('batman.jpg')\n",
    "print(batman_image.shape)\n",
    "\n",
    "# Store RGB values of all pixels in lists r, g and b\n",
    "for row in batman_image:\n",
    "    for temp_r, temp_g, temp_b in row:\n",
    "        r.append(temp_r)\n",
    "        g.append(temp_g)\n",
    "        b.append(temp_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distortions = []\n",
    "num_clusters = range(1, 7)\n",
    "\n",
    "# Create a list of distortions from the kmeans function\n",
    "for i in num_clusters:\n",
    "    cluster_centers, distortion = kmeans(batman_df[['scaled_red','scaled_blue','scaled_green']],i)\n",
    "    distortions.append(distortion)\n",
    "\n",
    "# Create a data frame with two lists, num_clusters and distortions\n",
    "elbow_plot = pd.DataFrame({'num_clusters':num_clusters,\n",
    "                            'distortions':distortions\n",
    "                          })\n",
    "\n",
    "# Create a line plot of num_clusters and distortions\n",
    "sns.lineplot(x='num_clusters', y='distortions', data = elbow_plot)\n",
    "plt.xticks(num_clusters)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get standard deviations of each color\n",
    "r_std, g_std, b_std = batman_df[['red', 'green', 'blue']].std()\n",
    "\n",
    "for cluster_center in cluster_centers:\n",
    "    scaled_r, scaled_g, scaled_b = cluster_center\n",
    "    # Convert each standardized value to scaled value\n",
    "    colors.append((\n",
    "        scaled_r * r_std / 255,\n",
    "        scaled_g * g_std / 255,\n",
    "        scaled_b * b_std / 255\n",
    "    ))\n",
    "\n",
    "# Display colors of cluster centers\n",
    "plt.imshow([colors])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TfidfVectorizer class from sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df = 0.75, max_features=50, min_df = 0.1, tokenizer=remove_noise)\n",
    "\n",
    "# Use the .fit_transform() method on the list plots\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 2\n",
    "\n",
    "# Generate cluster centers through the kmeans function\n",
    "cluster_centers, distortion = kmeans(tfidf_matrix.todense(),num_clusters)\n",
    "\n",
    "# Generate terms from the tfidf_vectorizer object\n",
    "terms = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    # Sort the terms and print top 3 terms\n",
    "    center_terms = dict(zip(terms, list(cluster_centers[i])))\n",
    "    sorted_terms = sorted(center_terms, key=center_terms.get, reverse=True)\n",
    "    print(sorted_terms[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the size of the clusters\n",
    "print(fifa.groupby('cluster_labels')['ID'].count())\n",
    "\n",
    "# Print the mean value of wages in each cluster\n",
    "print(fifa.groupby('cluster_labels')['eur_wage'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create centroids with kmeans for 2 clusters\n",
    "cluster_centers,_ = kmeans(fifa[scaled_features], 2)\n",
    "\n",
    "# Assign cluster labels and print cluster centers\n",
    "fifa['cluster_labels'], _ = vq(fifa[scaled_features], cluster_centers)\n",
    "print(fifa.groupby('cluster_labels')[scaled_features].mean())\n",
    "\n",
    "# Plot cluster centers to visualize clusters\n",
    "fifa.groupby('cluster_labels')[scaled_features].mean().plot(legend=True, kind='bar')\n",
    "plt.show()\n",
    "\n",
    "# Get the name column of first 5 players in each cluster\n",
    "for cluster in fifa['cluster_labels'].unique():\n",
    "    print(cluster, fifa[fifa['cluster_labels'] == cluster]['name'].values[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}