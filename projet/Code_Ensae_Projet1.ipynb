{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas import read_csv\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, KFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.linear_model import LassoCV, LinearRegression\n",
    "from sklearn.tree import  DecisionTreeRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Base de données et choix des Variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('C:/Users/wilfr/Downloads/streamer_20201104-121555.json.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xbrute = df[df.columns.difference(['text-sentiment_global'])] #Dataframe de Variables explicatives\n",
    "Y = df['text-sentiment_global'] #Variable à expliquer\n",
    "Xbrute\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Méthodes de Sélections de Variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2.1 Sélection par les corrélations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Corrélations linéaires entre la variable à expliquer et les variables explicatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matrice de Corrélation\n",
    "\n",
    " \n",
    "cor = df[['truncated','text-sentiment_compound','user-friends_count','user-listed_count','user-statuses_count']].corr() \n",
    "sns.heatmap (cor, annot = True, cmap = plt.cm.Reds) \n",
    "plt.show ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On va prendre les variables explicatives qui sont fortement corrélées,\n",
    "#linéairement avec notre variable à expliquer. 0.1 est choisi arbitrairement\n",
    "\n",
    "cor_target = abs (cor['user-friends_count'])\n",
    "relevant_features = cor_target [cor_target> 0.1] \n",
    "LesCorrLin = relevant_features.index.tolist()  #Nous retirons les variables fortement corrélées linéairement pour essayer de voir\n",
    "#celles qui sont aussi corrélées de manière non linéaire à notre y\n",
    "basecol = df.columns.tolist()\n",
    "for x in LesCorrLin :\n",
    "    basecol.remove(x)\n",
    "CorrNonLin = basecol\n",
    "basecol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Corrélations non linéaires entre la variable à expliquer et les variables explicatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrélation de Kendall, Test de rang des variables. H0: les classements des variables sont indépendants H1: Ils sont corrélés\n",
    "# Si la p-value est inférieure à 5% on rejette H0, donc on va choisir les variables qui ont une p-value supérieure à 0.05\n",
    "ListNonLin=[]\n",
    "for i in CorrNonLin:\n",
    "    ListNonLin.append(scipy.stats.kendalltau(df[\"user-friends_count\"],df[i]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FilterCorr = LesCorrLin + ListNonLin\n",
    "FilterCorr = FilterCorr.remove(\"user-friends_count\")\n",
    "#Nous avons l'ensemble des variables qui sont corrélés, selon 2 critères, avec notre variable explicative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.3 Corrélations linéaires entre les variables explicatives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Etude des corrélations entre variables explicatives \n",
    "InterCorr =  FilterCorr[1:]\n",
    "baseSec = base[InterCorr]\n",
    "plt.figure (figsize = (20,13)) \n",
    "cor = baseSec.corr () \n",
    "sns.heatmap (cor, annot = True, cmap = plt.cm.Reds) \n",
    "plt.show ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_features = cor[abs (cor)> 0.6] \n",
    "corr_features = corr_features.where(~(corr_features==1))\n",
    "corr_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtention de la Base de données totales au niveau de la méthode de sélection des variables basée sur les corrélations\n",
    "#On enlève les variables explicatives qui sont trop corrélées entre elles\n",
    "AutoCorr = []\n",
    "for x in AutoCorr:\n",
    "    FilterCorr.remove(x)\n",
    "FilterCorr\n",
    "Xcorr = base[FilterCorr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Utilisation de la Régression Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilisation de la régression Lasso \n",
    "X=Xbrute\n",
    "reg = LassoCV()\n",
    "reg.fit(X, Y)\n",
    "print(\"Best alpha using built-in LassoCV: %f\" % reg.alpha_)\n",
    "print(\"Best score using built-in LassoCV: %f\" %reg.score(X,y))\n",
    "coef = pd.Series(reg.coef_, index = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_coef = coef.sort_values() \n",
    "import matplotlib \n",
    "matplotlib.rcParams ['figure.figsize'] = (8.0, 10.0) \n",
    "imp_coef.plot (kind = \"barh\") \n",
    "plt.title (\"Importance des variables à l'aide du modèle Lasso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LossVar = imp_coef.index.where(imp_coef!=0)\n",
    "LossVar = pd.DataFrame(LossVar)\n",
    "LossVar = LossVar[~(LossVar==np.nan)].iloc[:,0].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Utilisation de la méthode RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= Xbrute\n",
    "models = [(\"RF\",RandomForestRegressor(random_state=0)),(\"GBR\", GradientBoostingRegressor(random_state=0)),(\"DTR\",DecisionTreeRegressor(random_state=0))]\n",
    "#no of features \n",
    "nof_list = np.arange (1,19)             \n",
    "\n",
    "#Meilleures variables \n",
    "           \n",
    "NbVar = []\n",
    "for nomodel, modele in models:\n",
    "    nof = 0 \n",
    "    high_score = 0 \n",
    "    for n in range (len (nof_list)): \n",
    "        X_train, X_test, y_train, y_test = train_test_split (X, Y, test_size = 0.2, random_state = 0) \n",
    "        model = modele\n",
    "        rfe = RFE (model, nof_list [n]) \n",
    "        X_train_rfe = rfe.fit_transform (X_train, y_train) \n",
    "        X_test_rfe = rfe.transform(X_test)\n",
    "        kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "        cv_results = cross_val_score(model, X_train_rfe, y_train, cv=10)\n",
    "        score = cv_results.mean()\n",
    "        if (score> high_score): \n",
    "            high_score = score \n",
    "            nof = nof_list [n]\n",
    "    NbVar.append((nof,nomodel,modele))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Xbrute\n",
    "Xrfe=[]\n",
    "RfeVars=[]\n",
    "cols = list (X.columns)\n",
    "for nb,nomodel, modele in NbVar:\n",
    "    rfe = RFE (modele, nb)             \n",
    "    #Transformation de données à l'aide de RFE \n",
    "    X_rfe = rfe.fit_transform (X, Y)  \n",
    "    #Ajustement des données au modèle \n",
    "    model.fit (X_rfe, Y)               \n",
    "    temp = pd.Series (rfe.support_, index = cols) \n",
    "    selected_features_rfe = temp [temp == True] .index \n",
    "    RfeVar = selected_features_rfe.tolist()\n",
    "    Xrfe.append((nomodel,base[RfeVar]))\n",
    "    RfeVars += RfeVar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y= make_classification()\n",
    "models = [(\"GNB\",GaussianNB()),(\"GBC\", GradientBoostingClassifier()),\n",
    "          (\"RFC\",RandomForestClassifier()),(\"DTC\",DecisionTreeClassifier())]\n",
    "\n",
    "Xtot= [(\"Brute\",Xbrute),(\"VarCorr\",Xcorr),(\"VarLoss\",Xloss),(\"VarBest\",Xbest)]\n",
    "index=[]\n",
    "colonne=[]\n",
    "for j,i in models:\n",
    "    index.append(j) \n",
    "    \n",
    "    \n",
    "for col,i in Xtot:\n",
    "    colonne.append(col)\n",
    "    \n",
    "results = []\n",
    "noms = []\n",
    "TabSorti = pd.DataFrame(index = index, columns = colonne)\n",
    "ScoreBest =0\n",
    "for nomdata, X in Xtot:\n",
    "    #Mettre à l'echelle les données\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X , Y, test_size=0.20, random_state=1)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train) \n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    for nomodel, modele in models:\n",
    "        kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "        cv_results = cross_val_score(modele, X_train, Y_train, cv=10)\n",
    "        scor = cv_results.mean()\n",
    "        TabSorti.at[nomodel, nomdata]= scor\n",
    "        if scor>  ScoreBest :\n",
    "            BestModel = nomodel\n",
    "            mod = modele\n",
    "            BestData = nomdata\n",
    "            ScoreBest = scor\n",
    "            Sqrt =cv_results.std()\n",
    "            bX_train, bX_test, bY_train, bY_test = X_train, X_test, Y_train, Y_test\n",
    "\n",
    "            \n",
    "\n",
    "print(\"Meilleur model : \",BestModel,\"\\n\",\"Meilleure modelisation :\",BestData)\n",
    "print(\"Sa moyenne : \", ScoreBest, \"\\n\",\"Son Ecart-type\",Sqrt)\n",
    "print(\"Table de sortie\")\n",
    "TabSorti"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}